#!/usr/bin/env python3
##############################################################################
# Copyright (C) 2025 Joel Klein                                              #
# All Rights Reserved                                                        #
#                                                                            #
# This work is licensed under the terms described in the LICENSE file        #
# found in the root directory of this source tree.                           #
##############################################################################

import sys
from pathlib import Path
from typing import Any

# Add project root to Python path
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

import numpy as np
import yaml

from lib.utils.logger import logger
"""
This script creates a custom latency lookup table for a crossbar-based MVM hardware.
The table estimates latency based on bit-widths of weights and activations and matrix dimensions.

The script takes YAML configuration files for:
1. Hardware parameters
2. Layer dimensions for the model
"""


def parse_int(value: str | int) -> int:
    """
    Parses a string or integer value into an integer.
    If the value is a string containing an expression (e.g., '64*224*224'),
    it evaluates the expression and returns the integer result.

    Args:
        value (str | int): The value to parse, can be a string or an integer

    Returns:
        int: The parsed integer value

    Raises:
        ValueError: If the value cannot be parsed as an integer
    """
    try:
        if isinstance(value, str) and '*' in value:
            return int(eval(value))
        else:
            return int(value)
    except Exception as e:
        raise ValueError(f"Cannot parse {value} as int") from e


def create_crossbar_latency_table(
        model_name: str, max_bit: int, layer_dimensions_yaml: list[dict[str,
                                                                        Any]],
        hardware_config: dict[str, Any],
        output_path: Path) -> tuple[np.ndarray, Path]:
    """
    Creates a latency lookup table for a crossbar-based MVM hardware for each layer x weight bit x activation bit.
    
    Args:
        model_name (str): Name of the model to use in the output filename
        max_bit (int): Maximum bit-width to sweep over for weights and activations
        layer_dimensions_yaml (list): List of layer dimensions from YAML file
        hardware_config (dict): Dictionary loaded from YAML with hardware parameters
        output_path (Path): Custom output path for the lookup table (optional)

    Returns:
        A 3D numpy array where dimensions are [layer_idx, weight_bits, activation_bits]
        Each entry represents the relative latency for the given configuration.
    """
    # Determine number of layers from the layer dimensions
    num_layers = len(layer_dimensions_yaml)
    logger.info(
        f"Creating latency table for {model_name} with {num_layers} layers")

    # Initialize the lookup table
    latency_table = np.zeros((num_layers, max_bit, max_bit))

    # Read crossbar config
    crossbar_size_m = hardware_config['crossbar']['size']['m']
    crossbar_size_n = hardware_config['crossbar']['size']['n']
    cell_resolution = hardware_config['crossbar']['resolution_weight_bits']
    input_resolution = hardware_config['crossbar']['resolution_input_bits']
    mvm_write_latency = hardware_config['crossbar']['mvm_write_latency']
    mvm_execute_latency = hardware_config['crossbar']['mvm_execute_latency']
    mapping_type = hardware_config['mapper']['mapping_type']

    logger.info(
        f"Using crossbar size: {crossbar_size_m}x{crossbar_size_n}, cell resolution: {cell_resolution} bits"
    )

    # For each layer in the model
    for layer_idx in range(num_layers):
        # Get layer information
        layer_info = layer_dimensions_yaml[layer_idx]
        layer_type = layer_info.get('type', 'Dense')

        m = parse_int(layer_info['output_dim'])
        n = parse_int(layer_info['input_dim'])
        mvm_invocations = parse_int(layer_info.get('mvm_invocations', 1))
        repeat_factor = parse_int(layer_info.get('repeat_factor', 1))

        logger.debug(
            f"Layer {layer_idx}: {layer_type}, m={m}, n={n}, "
            f"mvm_invocations={mvm_invocations}, repeat_factor={repeat_factor}"
        )

        # For each weight bit configuration
        for w_bit in range(1, max_bit + 1):
            # For each activation bit configuration
            for a_bit in range(1, max_bit + 1):
                # Number of weight bit-slices
                num_weight_slices = np.ceil(w_bit / cell_resolution)

                # Resolve mapping type aliases
                # Note: m (output_dim) maps to crossbar columns (M)
                #       n (input_dim) maps to crossbar rows (N)
                num_cols = m * num_weight_slices
                num_rows = n
                if mapping_type in ("of", "offset"):
                    # Offset: +1 column for bias correction
                    num_cols = num_cols + 1
                elif mapping_type in ("dc", "differential-column"):
                    # Differential column: 2 columns per weight (pos/neg)
                    num_cols = num_cols * 2
                elif mapping_type in ("dr", "differential-row"):
                    # Differential row: 2 rows per weight (pos/neg)
                    num_rows = num_rows * 2
                else:
                    raise ValueError(
                        f"Unknown mapping type: {mapping_type}. "
                        f"Use: offset (of), differential-column (dc), differential-row (dr)"
                    )

                num_mvm_writes = np.ceil(num_cols / crossbar_size_m) * np.ceil(
                    num_rows / crossbar_size_n)

                # Calculate the number of MVM executes
                # For simple Dense layers: mvm_invocations = 1
                # For Conv2D layers: mvm_invocations = O_H * O_W
                # For MHA layers:
                # - Dense layers (QKV, output proj, MLP): mvm_invocations = sequence_length
                # - MatMul layers (Q@K^T, Attention@V): mvm_invocations = sequence_length
                num_mvm_executes = mvm_invocations * num_mvm_writes * np.ceil(
                    a_bit / input_resolution)

                # Calculate the total latency for this configuration
                # repeat_factor = num_heads in MatMul for MHA (Q@K^T, Attention@V)
                latency = repeat_factor * (
                    num_mvm_writes * mvm_write_latency +
                    num_mvm_executes * mvm_execute_latency)

                # Store in the lookup table (zero-indexed)
                latency_table[layer_idx, w_bit - 1, a_bit - 1] = latency

    # Save the table
    output_path.parent.mkdir(parents=True, exist_ok=True)

    np.save(output_path, latency_table)

    logger.info(f'Latency table created and saved at {output_path}')
    return latency_table, output_path


if __name__ == '__main__':
    import argparse

    # Get the project root directory
    project_root = Path(__file__).parent.parent.parent

    parser = argparse.ArgumentParser(
        description=
        'Create a custom latency lookup table based on YAML configurations')

    parser.add_argument(
        '--model_name',
        type=str,
        default='qvgg16',
        help='Name to use for the output file (e.g., vgg16, resnet18)')

    parser.add_argument('--max_bit',
                        type=int,
                        default=8,
                        help='Maximum bit-width to consider')

    parser.add_argument(
        '--layer_dims_yaml',
        type=str,
        default=str(project_root /
                    'lib/simulator/vgg16_layer_dimensions.yaml'),
        help='YAML file path with layer dimensions')

    parser.add_argument('--hardware_config_yaml',
                        type=str,
                        default=str(project_root /
                                    'lib/simulator/hardware_config.yaml'),
                        help='YAML config file for hardware')

    parser.add_argument('--output_path',
                        type=Path,
                        default=None,
                        help='Custom output path for the lookup table')

    args = parser.parse_args()

    if args.output_path is None:
        args.output_path = Path(__file__).parent.resolve(
        ) / 'lookup_tables' / f'{args.model_name}_batch1_latency_table.npy'

    # Load hardware configuration YAML
    try:
        with open(args.hardware_config_yaml, 'r') as f:
            hardware_config = yaml.safe_load(f)
        logger.info(
            f'Loaded hardware configuration from {args.hardware_config_yaml}')
    except Exception as e:
        logger.error(f'Error loading hardware configuration: {e}')
        exit(1)

    # Load layer dimensions YAML
    try:
        with open(args.layer_dims_yaml, 'r') as f:
            dims_yaml = yaml.safe_load(f)
            layer_dimensions = dims_yaml['layer_dimensions']
        logger.info(f'Loaded layer dimensions from {args.layer_dims_yaml}')
        logger.info(f'Number of layers: {len(layer_dimensions)}')
    except Exception as e:
        logger.error(f'Error loading layer dimensions: {e}')
        exit(1)

    latency_table, output_path = create_crossbar_latency_table(
        args.model_name,
        max_bit=args.max_bit,
        layer_dimensions_yaml=layer_dimensions,
        hardware_config=hardware_config,
        output_path=args.output_path)

    logger.info(f'Example latency values for first layer:')
    logger.info(f'W=8bit, A=8bit: {latency_table[0, 7, 7]}')
    logger.info(f'W=4bit, A=4bit: {latency_table[0, 3, 3]}')
    logger.info(f'W=2bit, A=2bit: {latency_table[0, 1, 1]}')
